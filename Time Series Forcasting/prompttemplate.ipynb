{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.llms import Ollama\n",
    "from langchain.prompts import PromptTemplate\n",
    "import pandas as pd\n",
    "from langchain.chains import LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AHMED ABD ELGWAD\\AppData\\Local\\Temp\\ipykernel_24228\\2895630186.py:1: LangChainDeprecationWarning: The class `Ollama` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the :class:`~langchain-ollama package and should be used instead. To use it run `pip install -U :class:`~langchain-ollama` and import as `from :class:`~langchain_ollama import OllamaLLM``.\n",
      "  llm = Ollama(model=\"llama3.1\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Ollama(model='llama3.1')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm = Ollama(model=\"llama3.1\")\n",
    "llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('demand-forecasting-kernels-only/train.csv', parse_dates=['date'])\n",
    "test = pd.read_csv('demand-forecasting-kernels-only/test.csv', parse_dates=['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AHMED ABD ELGWAD\\AppData\\Local\\Temp\\ipykernel_24228\\2349737343.py:23: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
      "  chain = LLMChain(\n",
      "C:\\Users\\AHMED ABD ELGWAD\\AppData\\Local\\Temp\\ipykernel_24228\\2349737343.py:28: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  response = chain.run({\"train\": train})\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"**Data Analysis and Insights**\\n\\nAfter analyzing the supply chain dataset, I've identified several key trends and patterns, as well as anomalies and outliers.\\n\\n**1. Key Trends and Patterns:**\\n\\n* **Sales Volume:** The data shows a consistent sales volume across different items and stores over the years. However, there are fluctuations in sales volume throughout the year, with higher sales during the holiday season (December).\\n* **Store Performance:** Store 10 consistently has higher sales than other stores, indicating that it may be a high-demand store or have better inventory management.\\n* **Item Demand:** Item 50 is consistently among the top-selling items across all stores, suggesting that it is in high demand. Conversely, item 1 shows relatively low sales throughout the year.\\n\\n**2. Anomalies and Outliers:**\\n\\n* **Anomalous Sales Spike:** On December 29th, 2017 (row 912997), there was an unexpected spike in sales for store 10 with item 50, which deviates from the overall trend.\\n* **Low Sales Periods:** There are several instances where sales volumes dropped to almost zero or were very low throughout a specific period. These periods may indicate inventory shortages or supply chain disruptions.\\n\\n**3. Suggestions for Visualization:**\\n\\nTo better understand the data and provide actionable insights, I recommend creating the following visualizations:\\n\\n* **Line Graphs:**\\n\\t+ Daily/Weekly/Monthly Sales Volume Over Time (Store 10 vs. Other Stores)\\n\\t+ Item Sales Volume Over Time (Item 50 vs. Other Items)\\n* **Bar Charts:**\\n\\t+ Store-wise and Item-wise sales volume comparison\\n\\t+ Average Sales per Month or Quarter\\n* **Heatmaps:**\\n\\t+ Sales Volume Heatmap for Different Days of the Week\\n\\t+ Inventory Level Heatmap to track stock levels over time\\n\\n**Additional Insights and Recommendations:**\\n\\nBased on my analysis, I suggest:\\n\\n* Implementing a more robust inventory management system to minimize stockouts and delays.\\n* Conducting a detailed analysis of store performance and identifying potential improvement areas.\\n* Developing targeted marketing strategies for high-demand items like item 50.\\n\\nBy implementing these visualizations and recommendations, you can better understand the supply chain dynamics, identify areas for improvement, and make informed decisions to optimize sales and inventory management.\\n\\nWould you like me to elaborate on any of these points or suggest additional analyses?\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the prompt template\n",
    "demo_template = \"\"\"\n",
    "You are a data analyst. You are provided with a dataset about supply chain information.\n",
    "\n",
    "Here is the dataset structure:\n",
    "{train}\n",
    "\n",
    "Please analyze the data and provide insights about:\n",
    "1. Key trends and patterns in the supply chain (e.g., delays, high-demand items, etc.).\n",
    "2. Any anomalies or outliers in the data.\n",
    "3. Suggestions for visualization to better understand the data (e.g., bar charts, line graphs, or heatmaps).\n",
    "\n",
    "Respond with a detailed explanation and recommendations.\n",
    "\"\"\"\n",
    "\n",
    "# Create the prompt\n",
    "prompt_template = PromptTemplate(\n",
    "    input_variables=[\"train\"],\n",
    "    template=demo_template\n",
    ")\n",
    "\n",
    "from langchain.chains import LLMChain\n",
    "chain = LLMChain(\n",
    "    llm=llm,\n",
    "    prompt=prompt_template\n",
    ")\n",
    "\n",
    "response = chain.run({\"train\": train})\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Let's break down each column of your dataset:\\n\\n**1. date**\\n\\n* This column represents the date of sales.\\n* It contains a timestamp for every sale made, ranging from January 2013 to December 2017 (inclusive).\\n* The format is `YYYY-MM-DD`, which is a standard way to represent dates in many programming languages and databases.\\n\\nExample: `2013-01-01` means January 1st, 2013.\\n\\n**2. store**\\n\\n* This column represents the ID of the store where each sale was made.\\n* In this dataset, there's only one store with an ID of `10`.\\n* If you were to use this data in a real-world scenario, you'd likely have multiple stores with unique IDs, and this column would contain those IDs.\\n\\nExample: `10` is the ID of the single store in this dataset.\\n\\n**3. item**\\n\\n* This column represents the ID of the item that was sold.\\n* In this dataset, there's only one item with an ID of `50`.\\n* Similar to the `store` column, if you were using this data in a real-world scenario, you'd likely have multiple items with unique IDs.\\n\\nExample: `50` is the ID of the single item in this dataset.\\n\\n**4. sales**\\n\\n* This column represents the number of units sold on each date.\\n* It contains integers ranging from 10 to 82, which represent the quantity sold on each corresponding date.\\n* In a real-world scenario, this column would contain actual sales data for various items and stores.\\n\\nExample: On `2013-01-01`, 13 units were sold (whatever that item is!).\\n\\nNow, let's talk about how you can use this data in a Time Series Forecasting project:\\n\\n**Time Series Forecasting**\\n\\n* Given the date column, you're dealing with time-series data.\\n* Your goal is to predict future sales based on past trends and patterns.\\n* To achieve this, you'll need to analyze the relationships between different variables (e.g., date, store, item) and identify any underlying structures or seasonality in the data.\\n\\nSome potential steps for Time Series Forecasting with your dataset:\\n\\n1. **Cleaning and Preprocessing**:\\n\\t* Check for missing values, outliers, and inconsistencies.\\n\\t* Possibly normalize or scale the `sales` column to improve model performance.\\n2. **Exploratory Data Analysis (EDA)**:\\n\\t* Plot the time series data to visualize trends, seasonality, and potential anomalies.\\n\\t* Examine correlations between different variables (e.g., store, item) and sales.\\n3. **Model Selection**:\\n\\t* Choose an appropriate Time Series Forecasting model based on your EDA results (e.g., ARIMA, SARIMA, LSTM).\\n\\t* Consider incorporating other features, such as seasonality or holiday effects.\\n4. **Training and Evaluation**:\\n\\t* Split your data into training and testing sets.\\n\\t* Train your chosen model on the training set and evaluate its performance on the testing set.\\n\\nSome popular libraries for Time Series Forecasting in Python include:\\n\\n1. `statsmodels` (for classical time series analysis)\\n2. `pykalman` (for Kalman filter-based models)\\n3. `sktime` (a comprehensive library with many built-in models)\\n4. `Keras` or `TensorFlow` (for deep learning-based approaches)\\n\\nRemember to always evaluate your model's performance using metrics like Mean Absolute Error (MAE), Mean Squared Error (MSE), and Root Mean Squared Percentage Error (RMSPE).\\n\\nFeel free to ask if you have any specific questions about Time Series Forecasting or need help with implementing a particular technique!\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the prompt template\n",
    "demo_template = \"\"\"\n",
    "I want you to explain to me what data is {train},\n",
    "explain each column, what it represents and how to use this data in the Time series Forecasting project\n",
    "\"\"\"\n",
    "\n",
    "# Create the prompt\n",
    "prompt_template = PromptTemplate(\n",
    "    input_variables=[\"train\"],\n",
    "    template=demo_template\n",
    ")\n",
    "\n",
    "from langchain.chains import LLMChain\n",
    "chain = LLMChain(\n",
    "    llm=llm,\n",
    "    prompt=prompt_template\n",
    ")\n",
    "\n",
    "response = chain.run({\"train\": train})\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis Data:\n",
      " Based on the provided dataset, I've performed a thorough analysis to extract key trends, identify anomalies, and provide actionable insights.\n",
      "\n",
      "**Key Trends and Patterns:**\n",
      "\n",
      "1. **Increasing Sales Over Time**: The mean sales value has increased from 0 in 2013 to 52.25 in the latest available data point (2015-07-02). This suggests a positive trend in sales over time.\n",
      "2. **Store Count Consistency**: The count of stores remains relatively consistent at around 913,000 for all dates, indicating that the number of stores hasn't changed significantly over the analysis period.\n",
      "3. **Item Variety and Frequency**: There are 10 unique store values (1-10), with a mean value of 5.5, suggesting a moderate number of items sold across different stores. The item '25.500000' appears most frequently, implying it's a popular product.\n",
      "4. **Skewed Distribution**: The standard deviation for sales is relatively high (28.8), indicating a skewed distribution. This suggests that some stores or products may be selling significantly more than others.\n",
      "\n",
      "**Anomalies and Outliers:**\n",
      "\n",
      "1. **Zero Sales in 2013**: The minimum sales value is 0, which might indicate that some stores didn't sell any items on certain dates. Further investigation would be required to determine the cause.\n",
      "2. **High Maximum Sales Value (231)**: The maximum sales value is 231, which seems unusually high compared to the mean and median values. This could be an outlier or a one-off event.\n",
      "\n",
      "**Recommendations and Actionable Insights:**\n",
      "\n",
      "1. **Investigate Zero Sales**: Look into why some stores didn't sell any items on certain dates in 2013. This might be due to seasonal fluctuations, product unavailability, or other factors that can inform business decisions.\n",
      "2. **Analyze Skewed Distribution**: Explore the products and stores driving high sales variability. Are there specific promotions or marketing campaigns contributing to these differences? Identifying causes can help optimize strategies for maximum impact.\n",
      "3. **Focus on Top-Selling Items**: Prioritize the '25.500000' item, which appears most frequently in the data. Understand what makes this product so popular and explore ways to leverage its success across other products or marketing channels.\n",
      "4. **Monitor High-Maximum Sales Value (231)**: Investigate why this high sales value occurred and whether it's a one-time event or an ongoing trend. This might indicate opportunities for similar successful sales campaigns in the future.\n",
      "\n",
      "By analyzing these trends, identifying anomalies, and providing actionable insights, businesses can make informed decisions to optimize their operations, marketing strategies, and overall profitability.\n"
     ]
    }
   ],
   "source": [
    "# Analysis Data\n",
    "def analysis_data(train, llm):\n",
    "    # Extract dataset information\n",
    "    try:\n",
    "        data_info = train.describe().to_string()\n",
    "    except Exception as e:\n",
    "        raise ValueError(\"Unable to extract dataset information. Ensure 'train' is a valid DataFrame.\") from e\n",
    "\n",
    "    # Define the prompt for analysis\n",
    "    analysis_prompt = '''\n",
    "    You are a data analyst. You are provided with a dataset described as follows:\n",
    "    {data_info}\n",
    "\n",
    "    Please analyze the data and provide insights about:\n",
    "    1. Key trends and patterns in the data.\n",
    "    2. Any anomalies or outliers in the data.\n",
    "    3. Recommendations or actionable insights based on the analyzed data.\n",
    "    '''\n",
    "\n",
    "    # Define the prompt template\n",
    "    analysis_template = PromptTemplate(\n",
    "        input_variables=[\"data_info\"],\n",
    "        template=analysis_prompt\n",
    "    )\n",
    "\n",
    "    # Create a chain for analysis\n",
    "    analysis_chain = LLMChain(llm=llm, prompt=analysis_template)\n",
    "\n",
    "    # Run the chain on the data\n",
    "    analysis = analysis_chain.run(data_info=data_info)\n",
    "\n",
    "    # Return the analysis\n",
    "    return analysis\n",
    "\n",
    "# Example usage:\n",
    "result = analysis_data(train=train, llm=llm)\n",
    "print(\"Analysis Data:\\n\", result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis Data:\n",
      " This line of text appears to be output from a statistical analysis or summary of data, likely generated by a programming language such as Python using libraries like Pandas for data manipulation and NumPy for numerical computations.\n",
      "\n",
      "Here's a breakdown of what each part of this line means:\n",
      "\n",
      "1. **date**: This seems to represent the date at which the data was being summarized or analyzed. The output shows several dates: `2015-07-02 11:59:59.999999744`, `2014-04-02 00:00:00`, `2016-10-01 00:00:000`, and `2017-12-31 00:00:00`. These are likely dates related to the data or the analysis itself, possibly representing different quantiles (percentile values) such as min (minimum), max (maximum), 25%, 50% (median), and 75%.\n",
      "\n",
      "2. **store**, **item**, and **sales** columns:\n",
      "   - **count**: The total count of records is `913000`.\n",
      "   - **mean**: These are the mean values for each column, indicating that on average there were about 5.5 stores, 25.5 items, and $52.25 in sales per unit or transaction.\n",
      "   - **min**, **25%**, **50%** (median), **75%**, and **max**: These represent minimum, first quartile, median, third quartile, and maximum values for the respective columns:\n",
      "     - For **store**, the smallest value found was `1`, the middle 50% of values ranged from `3` to `5.5`, the highest recorded value was `10`.\n",
      "     - For **item**, the lowest count seen was `1`, the median (middle) and average counts were both about `25.5`, and the maximum observed was `50`.\n",
      "     - For **sales**, the lowest amount was `$0`, the middle 50% of sales ranged from about `$30` to `$47`, with a median value, and the highest recorded sale was over $231.\n",
      "\n",
      "3. **std**: This column shows the standard deviation for each variable:\n",
      "   - The standard deviation (std) for **store** is NaN (Not a Number), suggesting there might be issues with variance or that this measure doesn't apply in this context.\n",
      "   - For **item**, the standard deviation was `2.872283`, indicating a moderate spread of item counts around their mean value.\n",
      "   - For **sales**, the standard deviation was `28.801144`, suggesting a wide range of sales values.\n",
      "\n",
      "This output is likely from a data analysis or summary task, possibly used to understand and interpret some dataset's properties and trends.\n"
     ]
    }
   ],
   "source": [
    "def analysis_data(train, llm):\n",
    "    # Extract dataset information\n",
    "    try:\n",
    "        data_info = train.describe().to_string()\n",
    "    except Exception as e:\n",
    "        raise ValueError(\"Unable to extract dataset information. Ensure 'train' is a valid DataFrame.\") from e\n",
    "\n",
    "    # Define the prompt for analysis\n",
    "    analysis_prompt = '''\n",
    "    explain this line \n",
    "    {data_info}\n",
    "    '''\n",
    "\n",
    "    # Define the prompt template\n",
    "    analysis_template = PromptTemplate(\n",
    "        input_variables=[\"data_info\"],\n",
    "        template=analysis_prompt\n",
    "    )\n",
    "\n",
    "    # Create a chain for analysis\n",
    "    analysis_chain = LLMChain(llm=llm, prompt=analysis_template)\n",
    "\n",
    "    # Run the chain on the data\n",
    "    analysis = analysis_chain.run(data_info=data_info)\n",
    "\n",
    "    # Return the analysis\n",
    "    return analysis\n",
    "\n",
    "# Example usage:\n",
    "result = analysis_data(train=train, llm=llm)\n",
    "print(\"Analysis Data:\\n\", result)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
